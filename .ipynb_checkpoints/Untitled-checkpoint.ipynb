{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, deque\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_signals(transaction_history):\n",
    "    buy, sell, hold = 0, 0, 0\n",
    "    for _, _, a in transaction_history:\n",
    "        if a == 0:\n",
    "            hold += 1\n",
    "        if a == 1:\n",
    "            buy += 1\n",
    "        if a == 2:\n",
    "            sell += 1\n",
    "    total = hold + buy + sell\n",
    "    print('hold {}%, buy {}%, sell {}%'.format(hold/total, buy/total, sell/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2014, 1, 1)\n",
    "end = datetime.datetime(2018, 1, 1)\n",
    "train_df, test_df = get_stock_data('AAPL', start, end, 0.8)\n",
    "\n",
    "train_df = create_df(train_df, 3)\n",
    "\n",
    "train_data = np.array(train_df[['norm_adj_close', 'norm_bb_width', 'norm_close_sma_ratio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trader1:\n",
    "    \n",
    "    def __init__(self, act_size, state_size, is_trained, model_path=None):\n",
    "        self.state_size = state_size\n",
    "        self.act_size = act_size # 3\n",
    "        self.history = deque(maxlen=1000) # historical stock data <state, action, reward, new state>\n",
    "        self.is_trained = is_trained\n",
    "        self.bought_history = []\n",
    "        self.transactions = []\n",
    "        \n",
    "        self.alpha = 0.9\n",
    "        self.alpha_min = 0.1\n",
    "        self.alpha_decay = 0.99\n",
    "        self.gamma = 0.95\n",
    "        \n",
    "        if self.is_trained:\n",
    "            self.deep_net = torch.load(model_path)\n",
    "        else:\n",
    "            self.deep_net = self.model()\n",
    "    \n",
    "    def model(self):\n",
    "        deep_net = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(self.state_size, 64)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('fc2', nn.Linear(64, 32)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('fc3', nn.Linear(32, 8)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('output', nn.Linear(8, self.act_size))\n",
    "        ]))\n",
    "        self.deep_net = deep_net\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.deep_net.parameters(), lr=0.002)\n",
    "        return self.deep_net\n",
    "    \n",
    "    def act(self, state):\n",
    "        state = torch.tensor(state).float()\n",
    "        if not self.is_trained:# and \n",
    "            if np.random.rand() < self.alpha:\n",
    "                #print('not trained random walker')\n",
    "                return np.random.randint(0, self.act_size)\n",
    "            else:\n",
    "                #print('not trained deep q learning')\n",
    "                qs = self.deep_net.forward(state)\n",
    "                return np.argmax(action)\n",
    "        else:\n",
    "            qs = self.deep_net.forward(state)\n",
    "            return np.argmax(action)\n",
    " \n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        mini_batch = []\n",
    "        random_indices = np.random.choice(range(0, len(self.history)), batch_size, replace=False)\n",
    "        for i in random_indices: #range(len(self.history)-batch_size-1, len(self.history)-1):\n",
    "            mini_batch.append(self.history[i])\n",
    "        \n",
    "        for state, action, reward, next_state in mini_batch:\n",
    "            self.optimizer.zero_grad()\n",
    "            # print('action{}, max future return'.format(action, torch.max(self.deep_net.forward(torch.tensor(next_state).float()).data)))\n",
    "#             with torch.no_grad():\n",
    "#                 max_future = self.deep_net.forward(torch.tensor(next_state).float()).numpy().max()\n",
    "            max_future, _ = torch.max(self.deep_net.forward(torch.tensor(next_state).float()),0)\n",
    "                #print(max_future)\n",
    "            q_target_action = reward + self.gamma * max_future\n",
    "            #print('max return for action {}'.format(q_target_action))\n",
    "            q_pred = self.deep_net.forward(torch.tensor(state).float())\n",
    "            #print('pred {} {}'.format(q_pred, q_pred.data[0]))\n",
    "            q_target = q_pred.clone()\n",
    "            q_target.data[action] = q_target_action\n",
    "            #print('updated target {}'.format(q_target.data))\n",
    "            \n",
    "            self.loss = self.criterion(q_pred, q_target.detach())\n",
    "            #print(q_pred, q_target)\n",
    "            #print('loss {}'.format(loss.item()))\n",
    "            \n",
    "            \n",
    "            self.loss.backward(retain_graph=True)\n",
    "            \n",
    "            self.optimizer.step()\n",
    "       # print(self.deep_net.output.weight)\n",
    "        if self.alpha >= self.alpha_min:\n",
    "            self.alpha *= self.alpha_decay\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trader = Trader1(act_size=3, state_size=4, is_trained=False)\n",
    "\n",
    "cntr = 0\n",
    "epochs = 2000\n",
    "batch_size = 10\n",
    "num_shares = 0\n",
    "returns=[0]\n",
    "\n",
    "for e in range(500):\n",
    "    num_shares = 0\n",
    "    returns=[0]\n",
    "    trader.transactions = []\n",
    "    trader.history.clear()\n",
    "    trader.bought_history = []\n",
    "    for i, state in enumerate(train_data):\n",
    "        current_price = state[0]\n",
    "\n",
    "        try:\n",
    "            next_state = train_data[i+1]\n",
    "        except:\n",
    "            break\n",
    "        if num_shares > 0:\n",
    "            # state = np.append(state, 0)\n",
    "            returns.append(get_return_since_entry(trader.bought_history, current_price))\n",
    "        else:\n",
    "            # state = np.append(state, 1)\n",
    "            returns.append(returns[-1])\n",
    "        state = np.append(state, num_shares)\n",
    "        action = trader.act(state)\n",
    "        trader.transactions.append((i, current_price, action))\n",
    "\n",
    "        #print('action {}', action)\n",
    "\n",
    "        if action == 0: #hold\n",
    "            if num_shares > 0:\n",
    "                previous_price = train_data[i-1][0]\n",
    "                reward = current_price-previous_price\n",
    "            else:\n",
    "                reward = 0\n",
    "            \n",
    "        if action == 1: # buy\n",
    "            reward = 0\n",
    "            trader.bought_history.append(current_price)\n",
    "            num_shares += 1\n",
    "        if action == 2:\n",
    "            if num_shares > 0:\n",
    "                reward = current_price - trader.bought_history[0]\n",
    "               # print('sell {}'.format(trader.bought_history[0]))\n",
    "                #print('reward', reward)\n",
    "                trader.bought_history.pop(0)\n",
    "                num_shares -= 1\n",
    "            else:\n",
    "                reward = -100\n",
    "\n",
    "        # update the state of next_state, hold shares or not\n",
    "#         if num_shares > 0:\n",
    "#             next_state = np.append(next_state, 0)\n",
    "#         else:\n",
    "#             next_state = np.append(next_state, 1)\n",
    "        next_state = np.append(next_state, num_shares)\n",
    "        trader.history.append([state, action, reward, next_state])\n",
    "        #print(len(trader.history))\n",
    "        if len(trader.history) > batch_size:\n",
    "            trader.replay(batch_size)  \n",
    "            \n",
    "    if (e+1) % 1 == 0:\n",
    "        model_name = 'model_epoch_trial'+str(e+1)  + '.pth'\n",
    "        torch.save(trader.deep_net.state_dict(), model_name)\n",
    "        #print(trader.deep_net.output.weight)\n",
    "        print('Trained {} epochs '.format(e+1))\n",
    "        get_invested_capital(trader.transactions, returns)\n",
    "        analyze_signals(trader.transactions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(4, 64)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('fc2', nn.Linear(64, 32)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('fc3', nn.Linear(32, 8)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('output', nn.Linear(8, 3))\n",
    "        ]))\n",
    "model.load_state_dict(torch.load('model_epoch_trial40.pth'))\n",
    "b=model.fc1.weight\n",
    "\n",
    "model_1 = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(4, 64)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('fc2', nn.Linear(64, 32)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('fc3', nn.Linear(32, 8)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('output', nn.Linear(8, 3))\n",
    "        ]))\n",
    "model_1.load_state_dict(torch.load('model_epoch_trial44.pth'))\n",
    "a=model_1.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr = 0\n",
    "\n",
    "# returns = [0]\n",
    "num_shares = 0\n",
    "# losses = []\n",
    "# #trader.deep_net.eval()\n",
    "test_transactions = []\n",
    "returns = [0]\n",
    "bought_history = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, state in enumerate(train_data):\n",
    "        current_price = state[0]\n",
    "        try:\n",
    "            next_state = train_data[i+1]\n",
    "        except:\n",
    "            print('End of data!')\n",
    "            break\n",
    "\n",
    "        if len(bought_history) > 0:\n",
    "            returns.append(get_return_since_entry(bought_history, current_price)) \n",
    "        else:\n",
    "            returns.append(returns[-1])\n",
    "        #print('return since entry {}'.format(returns[-1]))\n",
    "\n",
    "        state = np.append(state, num_shares)\n",
    "#         if num_shares > 0:\n",
    "#             state = np.append(state, 0)\n",
    "\n",
    "#         else:\n",
    "#             state = np.append(state, 1)\n",
    "        # print(state)\n",
    "        state = torch.tensor(state).float()\n",
    "        qs = model(state)\n",
    "        action = np.argmax(qs.numpy())\n",
    "        print('action', action, 'num shares', num_shares, state,qs)\n",
    "\n",
    "        if action == 1:\n",
    "            num_shares += 1\n",
    "            bought_history.append(current_price)\n",
    "        if action == 2:\n",
    "            num_shares -= 1\n",
    "        test_transactions.append((i, current_price, action))\n",
    "        #print(num_shares, trader.deep_net.forward(torch.tensor(state).float()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_signals(test_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_resualts(test_transactions, returns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
